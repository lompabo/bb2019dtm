{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Language Recognition\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "We want to design a system for automatically detecting in which language a short text is written. In particular, we want to distinguish between English, French, and Italian.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "> The doctor, who was the family physician, saluted him, but he scarcely took any notice. --> English\n",
    "\n",
    "> J'ai couru chez toi, je ne t'ai plus trouvée, tu sais la parole que je t'avais donnée, je la Bens. --> French\n",
    "\n",
    "> Conosci tu qualche hossanieh poco scrupoloso che si possa comperare con un bel pugno d'oro? --> Italian\n",
    "\n",
    "This is a simple, but realistic problem, which we want to solve using a traditional (non deep) Multi Layer Perceptron.\n",
    "\n",
    "Compared to our dummy example there is **one main difference: each sample in the dataset is a piece of text, rather than a vector of numbers**.\n",
    "\n",
    "Before we can think of learning a MLP to solve this problem, we need to convert the input in a form that the Neural Network can understand.\n",
    "\n",
    "The traditonal way to do it is by computing for each piece of text a set of numeric _features_ (e.g. number characters, number of vowels...). By doing so, we associate each example to a feature vector, which can be fed to the MLP.\n",
    "\n",
    "The main goal of this exercise will be to design a good set of features for the considered problem. We will come to that at the end of the notebook: first, we need to understand how the overall solution approach works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First of All...\n",
    "\n",
    "If you are using this notebook from Google Colab, you need to fetch the necessary resources by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir resources\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/AirQualityUCI.csv\n",
    "!mv AirQualityUCI.csv resources\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/lr_train.txt\n",
    "!mv lr_train.txt resources/\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/lr_test.txt\n",
    "!mv lr_test.txt resources/\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/lutil.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The first thing to do is loading the training set in its raw format. We will do it by using a function that has been pre-coded and stored in a separate \".py\" file (prepared for this lecture): we will import the function via the instruction:\n",
    "\n",
    "```python\n",
    "import lutil\n",
    "```\n",
    "\n",
    "where `ltuil.py` is the name of the file to import. The function is called `load_data` and has the signature:\n",
    "\n",
    "```python\n",
    "def load_lr_data(file_name)\n",
    "```\n",
    "\n",
    "which is quite intuitive. The function returns a tuple with two elements, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lutil\n",
    "\n",
    "# Load the training data\n",
    "text_train, lang_train = lutil.load_lr_data('lr_train.txt')\n",
    "# Load the test data\n",
    "text_test, lang_test = lutil.load_lr_data('lr_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `text_train` is a list containing all the short texts in the trainin test, and `lang_train` is a list with the corresponding language. `text_test` and `lang_test` contain the same information for the test set.\n",
    "\n",
    "We can inspect them by printing the first few elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The doctor, who was the family physician, saluted him, but he scarcely took any notice. --> english\n",
      "Cette réserve faite, et faite en toute sévérité, il nous est impossible de ne pas admirer, qu'ils réussissent ou non, les glorieux combattants de l'avenir, les confesseurs de l'utopie. --> french\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(text_train[i], '-->', lang_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can write some code for extracting the features.\n",
    "\n",
    "We will write a function that returns a numpy array with:\n",
    "\n",
    "* One row for each example in the dataset\n",
    "* One column for each feature\n",
    "\n",
    "Hence, the structure of our code will be (more or less):\n",
    "\n",
    "```python\n",
    "def extract_features(text):\n",
    "    # Prepare a data structure to store the results\n",
    "    res = []\n",
    "    # Loop over all pieces of text\n",
    "    for lne in text:\n",
    "        row = []\n",
    "        # Feature 1:\n",
    "        v = # code to extract the feature\n",
    "        row.append(v)\n",
    "        # Feature 2:\n",
    "        v = # code to extract the feature\n",
    "        row.append(v)\n",
    "        ...\n",
    "        # Append the row\n",
    "        res.append(row)\n",
    "    return np.array(res)\n",
    "```\n",
    "\n",
    "With `np.array(res)` we build a numpy array with the same structure and content of the `res` data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of feature extraction code that is actually working is given here.\n",
    "\n",
    "The features used in thes code are just examples: they do not work very well for detecting the language, but they provide good examples of what you can do to extract a features.\n",
    "\n",
    "You main job in this exercise will be to write code for extracting different features.\n",
    "\n",
    "The code starts with the iniitialization of several lists (e.g. `common_alphabet`) that contain characters appearing in our training and test set. They are provided for convenience, since they may be useful for computing some features. The `u` before each string in the lists is there because the text contains all manners of accented letters, which requires to use the Unicode format for representing string characters. The `u` tells python that the string should use the Unicode format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "common_alphabet = ['(', '«', ',', '0', '4', '8', '»', 'D', 'H', 'L', 'P', 'T', 'X', 'd', 'h', 'l', 'p', 't', 'x', u\"'\", '°', '3', '7', ';', '?', 'C', 'G', 'K', 'O', 'S', 'W', '[', '_', 'c', 'g', 'k', 'o', 's', 'w', '\\n', '\"', '*', '.', '2', '6', ':', 'B', 'F', 'J', 'N', 'R', 'V', 'Z', 'b', 'f', 'j', 'n', 'r', 'v', 'z', '!', ')', '-', '1', '5', '9', 'A', 'E', 'I', 'M', 'Q', '', 'Y', ']', 'a', 'e', 'i', 'm', 'q', 'y', ' ', '\\t']\n",
    "global_alphabet = ['(', '«', ',', '0', '4', '8', '»', 'D', 'Ç', 'H', 'L', 'P', 'T', 'X', 'd', 'ç', 'h', 'ë', 'l', 'ï', 'p', 't', 'x', 'û', u\"'\", '+', '/', '°', '3', '7', ';', '?', 'À', 'C', 'G', 'È', 'K', 'O', 'S', 'Ô', 'W', '[', '_', 'à', 'c', 'g', 'è', 'k', 'ì', 'o', 's', 'ô', 'w', 'ü', ' ', '\\n', '\"', '&', '*', '.', '2', '6', ':', 'B', 'F', 'É', 'J', 'N', 'R', 'V', 'Z', 'b', 'f', 'é', 'j', 'n', 'ñ', 'r', 'v', 'ù', 'z', '\\t', '!', ')', '-', '1', '5', '9', 'º', 'A', 'Â', 'E', 'Æ', 'I', 'Ê', 'M', 'Q', '', 'Y', ']', 'a', 'â', 'e', 'æ', 'i', 'ê', 'm', 'î', 'q', 'ò', 'ö', 'y']\n",
    "vowels = ['ë', 'û', 'À', 'È', 'O', 'Ô', 'à', 'è', 'ì', 'o', 'ô', 'ü', 'É', 'é', 'ù', 'A', 'Â', 'E', 'Æ', 'I', 'Ê', '', 'Y', 'a', 'â', 'e', 'æ', 'i', 'ê', 'î', 'ò', '', 'ö', 'y', 'ï']\n",
    "consonants = ['D', 'p', 't', 'x', 'Ç', 'H', 'L', 'P', 'T', 'X', 'd', 'ç', 'h', 'l', 'C', 'G', 'K', 'S', 'W', 'c', 'g', 'k', 's', 'w', 'B', 'F', 'J', 'N', 'R', 'V', 'Z', 'b', 'f', 'j', 'n', 'ñ', 'r', 'v', 'z', 'M', 'Q', 'm', 'q', ]\n",
    "numbers = ['0', '4', '8', '3', '7', '2', '6', '1', '5', '9', ]\n",
    "separators = ['(', '«', ',', '»', \"'\", '+', '/', '°', ';', '?', '[', '_', ' ', '\\n', '\"', '&', '*', '.', ':', '\\t', '!', ')', '-', 'º', ']']\n",
    "separators_as_string = ''.join(separators)\n",
    "\n",
    "def extract_features(text):\n",
    "    # Prepare a data structure to store the results\n",
    "    res = []\n",
    "    # Loop over all pieces of text\n",
    "    for lne in text:\n",
    "        # PREPARE A ROW FOR THE DATASET\n",
    "        row = []\n",
    "        # Obtain the list of words (this is useful to extract many\n",
    "        # features)\n",
    "        words = [w.strip(separators_as_string) for w in lne.split()]\n",
    "        words = [w for w in words if len(w) > 0]\n",
    "\n",
    "        # EXTRACT FEATURES\n",
    "        # F0: Number of words\n",
    "        nwords = len(words)\n",
    "        row.append(nwords)\n",
    "        # F1: Number of characters per word\n",
    "        # NOTE: float(nwords) is necessary to avoid an integer division\n",
    "        ncharperword = len(lne) / float(nwords)\n",
    "        row.append(ncharperword)\n",
    "        # F2: Get number of vowels\n",
    "        # NOTE: \"lower()\" makes the string lower case\n",
    "        nvowels = len([c for c in lne if c.lower() in vowels])\n",
    "        row.append(nvowels)\n",
    "        # F3: Get the number of words starting with \"p\"\n",
    "        nstartp = len([w for w in words if w[0] == u'p'])\n",
    "        row.append(nstartp)\n",
    "        # F4: Get number of occurences of the word \"cookie\"\n",
    "        ncookie = len([w for w in words if w == 'cookie'])\n",
    "        row.append(ncookie)\n",
    "        # F5: Get number of occurrences of either \"cookie\" or \"wookie\"\n",
    "        ncwookie = len([w for w in words if w in ['cookie', 'wookie']])\n",
    "        row.append(ncwookie)\n",
    "        \n",
    "        # APPEND THE ROW\n",
    "        res.append(row)\n",
    "    # Return the result\n",
    "    return np.array(res)\n",
    "\n",
    "x_train = extract_features(text_train)\n",
    "x_test = extract_features(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.          5.8        27.          1.          0.          0.        ]\n",
      " [29.          6.34482759 57.          1.          0.          0.        ]\n",
      " [20.          5.5        35.          0.          0.          0.        ]]\n",
      "[[23.          5.26086957 34.          2.          0.          0.        ]\n",
      " [15.          6.8        33.          1.          0.          0.        ]\n",
      " [12.          7.33333333 28.          1.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:3, ])\n",
    "print(x_test[:3, ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is almost ready: we just need to normalize it. This is needed because in this lecture we will employ both a linear classifier and Decision Trees: Decision Trees can deal easily wiht unscaled data, but linear classifiers have trouble with them.\n",
    "\n",
    "Scikit-learn provides some useful methods for normalization and standardization. We didn't employ them in the last lecture because we were dealing with a very peculiar situation (i.e. a time series).\n",
    "\n",
    "In detail, normalization is handled via \"scalers\". A scaler is treated similarly to a ML model:\n",
    "\n",
    "- Some parameters can be specified a construction time\n",
    "- The scaler will need to be trained, which allow sklear to obtain the data-dependent parameters (e.g. $\\mu$ and $\\sigma$)\n",
    "- The scaler can then be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_norm = scaler.transform(x_train)\n",
    "x_test_norm = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalers can also easily apply the inverse transformation (i.e. \"unscale\" the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the standardized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7813303  -0.20776644 -0.77763905 -0.18827856  0.          0.        ]\n",
      " [ 0.60535866  0.63376133  0.71106802 -0.18827856  0.          0.        ]\n",
      " [-0.28608424 -0.67113933 -0.3806505  -0.9216643   0.          0.        ]]\n",
      "[[ 0.01106339 -1.04049453 -0.43027407  0.54510718  0.          0.        ]\n",
      " [-0.7813303   1.33680985 -0.47989764 -0.18827856  0.          0.        ]\n",
      " [-1.07847794  2.16058387 -0.72801548 -0.18827856  0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_norm[:3, :])\n",
    "print(x_test_norm[:3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be no \"cookie\" and no \"wookie\" in this stories :-) That's why feature #4 and feature #5 are always zero.\n",
    "\n",
    "Ok, now our input is ready.\n",
    "\n",
    "We still need to do something about the output though. Currently, we have access for each example to the language as a string, i.e. \"english\", \"french\", or \"italian\".\n",
    "\n",
    "We will need to convert them to integer values. Once again, to make your life simpler, a function to conver string classes to integer classes has been provided in the \"lutil.py\" file. The signature is:\n",
    "\n",
    "```python\n",
    "def labels_to_int(data, labels)\n",
    "```\n",
    "\n",
    "where: \n",
    "\n",
    "* `data` is an array of strings\n",
    "* `labels` is a list with the class names\n",
    "\n",
    "The function return a list of integers. In particular, each string is replaced with its position in the `labels` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "languages = ['english', 'french', 'italian']\n",
    "\n",
    "# Convert the training and the test set\n",
    "y_train = lutil.labels_to_int(lang_train, languages)\n",
    "y_test = lutil.labels_to_int(lang_test, languages)\n",
    "\n",
    "# Let's have a look at the result\n",
    "print(y_train[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We will now train a linear _classifier_ (Logistic Regression) to address this language detection problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LogisticRegression(solver='saga', tol=1e-4, max_iter=10)\n",
    "model.fit(x_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain the predictions in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0] [0 1 0]\n",
      "[0 2 1] [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "p_train = model.predict(x_train_norm)\n",
    "p_test = model.predict(x_test_norm)\n",
    "\n",
    "print(p_train[:3], y_train[:3])\n",
    "print(p_test[:3], y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the model accuracy by relying again on functions from the \"metrics\" submodule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.68\n",
      "Accuracy on the test set: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, p_train)\n",
    "acc_test = metrics.accuracy_score(y_test, p_test)\n",
    "\n",
    "print('Accuracy on the training set: %.2f' % acc_train)\n",
    "print('Accuracy on the test set: %.2f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees in Scikit-learn\n",
    "\n",
    "Decision trees are actually quite easy to use in scikit-learn. As usual, we just need to:\n",
    "\n",
    "- Instantiate a tree model\n",
    "- Train\n",
    "- Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.98\n",
      "Accuracy on the test set: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(x_train_norm, y_train)\n",
    "\n",
    "p_train = model.predict(x_train_norm)\n",
    "p_test = model.predict(x_test_norm)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, p_train)\n",
    "acc_test = metrics.accuracy_score(y_test, p_test)\n",
    "\n",
    "print('Accuracy on the training set: %.2f' % acc_train)\n",
    "print('Accuracy on the test set: %.2f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are significantly better than before!\n",
    "\n",
    "The main reason is that DTs can deal with non-linear input/output relations, that cannot be effectively managed by linear classifiers.\n",
    "\n",
    "DTs have also a tendency to happily overfit, though, and this is definitely happening right now.\n",
    "\n",
    "A simple method to reduce overfitting consists in enforcing some bias. In the case of DTs, we can for example limit the depth, or the minimum number of examples per leaf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.73\n",
      "Accuracy on the test set: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier(min_samples_leaf=10)\n",
    "model.fit(x_train_norm, y_train)\n",
    "\n",
    "p_train = model.predict(x_train_norm)\n",
    "p_test = model.predict(x_test_norm)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, p_train)\n",
    "acc_test = metrics.accuracy_score(y_test, p_test)\n",
    "\n",
    "print('Accuracy on the training set: %.2f' % acc_train)\n",
    "print('Accuracy on the test set: %.2f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not always effective, though: a much better method in practice consists in using _ensembles_ of trees, such as Random Forest or Gradient Boosted Trees. Once again, these systems are easy to use in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 0.98\n",
      "Accuracy on the test set: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = ensemble.RandomForestClassifier(n_estimators=50)\n",
    "model.fit(x_train_norm, y_train)\n",
    "\n",
    "p_train = model.predict(x_train_norm)\n",
    "p_test = model.predict(x_test_norm)\n",
    "\n",
    "acc_train = metrics.accuracy_score(y_train, p_train)\n",
    "acc_test = metrics.accuracy_score(y_test, p_test)\n",
    "\n",
    "print('Accuracy on the training set: %.2f' % acc_train)\n",
    "print('Accuracy on the test set: %.2f' % acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not even this is working particularly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Elephant in the Room\n",
    "\n",
    "Why are we still overfitting? There is a simple reason that we have overlooked so far: the current set of features may be meaning less. Let's have a second look at them:\n",
    "\n",
    "```\n",
    "# F0: Number of words\n",
    "nwords = len(words)\n",
    "row.append(nwords)\n",
    "# F1: Number of characters per word\n",
    "# NOTE: float(nwords) is necessary to avoid an integer division\n",
    "ncharperword = len(lne) / float(nwords)\n",
    "row.append(ncharperword)\n",
    "# F2: Get number of vowels\n",
    "# NOTE: \"lower()\" makes the string lower case\n",
    "nvowels = len([c for c in lne if c.lower() in vowels])\n",
    "row.append(nvowels)\n",
    "# F3: Get the number of words starting with \"p\"\n",
    "nstartp = len([w for w in words if w[0] == u'p'])\n",
    "row.append(nstartp)\n",
    "# F4: Get number of occurences of the word \"cookie\"\n",
    "ncookie = len([w for w in words if w == 'cookie'])\n",
    "row.append(ncookie)\n",
    "# F5: Get number of occurrences of either \"cookie\" or \"wookie\"\n",
    "ncwookie = len([w for w in words if w in ['cookie', 'wookie']])\n",
    "row.append(ncwookie)\n",
    "```\n",
    "\n",
    "Except for F2 and F1, the other features are pure garbage. That has been done in purpose! These fetures are good examples of _what you can extract_ from data, but definitely poor examples of _what you should extract_.\n",
    "\n",
    "In short: we'd better refine our feature set. This requires some deeper insight into the performance of our classifier and into its behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Before the true action starts, it is worth introducing a slighly more advanced tool to look at the accuracy a classifier, called \"confusion matrix\".\n",
    "\n",
    "Behind the fancy name, a confusion matrix is just a data structure that stores both correct and wrong prediction for a classifier. In detail, every entry $C_{i,j}$ in the matrix tells how many examples having _true class $i$_ have been _classified as having class $j$_.\n",
    "\n",
    "Basically, the true classes act as row labels and the predicted classes as column labels.\n",
    "\n",
    "|           | C1 (pred) | C2 (pred) | C3 (pred) | ... |\n",
    "|:---------:|:---------:|:---------:|:---------:|-----|\n",
    "| **C1 (true)** |  C1 classified as C1 | C1 classified as C2 | C1 classified as C3 | ...    |\n",
    "| **C2 (true)** | ... | ... | ... | ... |\n",
    "| **C3 (true)** | ... | ... | ... | ... |\n",
    "|    **...**    | ... | ... | ... | ... |\n",
    "\n",
    "The `lutil` file that we have previously loaded contains a function to display a figure with the confusion matrix. The signature of the function is:\n",
    "\n",
    "```python\n",
    "def plot_confusion_matrix(targets, preds, classes):\n",
    "```\n",
    "\n",
    "where: \n",
    "\n",
    "* `targets` is an array with the true classes (as integers)\n",
    "* `preds` is an array with the predicted classes (as integers)\n",
    "* `classes` is a list with the names of the classes (i.e. the laguages, in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First we need to obtain the predicted classes\n",
    "# NOTE: we have already seen how to do it\n",
    "y_preds = model.predict(x_test_norm)\n",
    "\n",
    "# Then we can display the confusion matrix\n",
    "lutil.plot_confusion_matrix(y_test, y_preds, languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is cool because it enables one to see at a glance where most of the classification errors are. In particular:\n",
    "\n",
    "* Elements on the diagonal correspond to the number of exact classifications: they should be as large as possible.\n",
    "* Elements outside of the diagonal tell us how many misclassification of each type have occurred.\n",
    "\n",
    "In our case, for example, we have trouble distinguishing between Italian and French, and some difficulties with French and English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Scores\n",
    "\n",
    "All tree based model enable the computation of \"importance scores\" for each features, that reflect the average relative reduction in the training metric (e.g. entropy) associated to splits over the feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 (0.375653)\n",
      "2. feature 2 (0.309887)\n",
      "3. feature 0 (0.208676)\n",
      "4. feature 3 (0.105784)\n",
      "5. feature 5 (0.000000)\n",
      "6. feature 4 (0.000000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_train.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(x_train.shape[1]), indices)\n",
    "plt.xlim([-1, x_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, F1 and F2 are the most important for the classification.\n",
    "\n",
    "Keep in mind that this information refers to the training set: hence, if a feature is important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
