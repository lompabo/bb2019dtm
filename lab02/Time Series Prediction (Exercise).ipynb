{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex - Univariate Time Series Prediction\n",
    "\n",
    "Here we will try using decision trees for a regression task, namely the time series prediction problem from the previous lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First of All...\n",
    "\n",
    "If you are using this notebook from Google Colab, you need to fetch the necessary resources by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir resources\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/AirQualityUCI.csv\n",
    "!mv AirQualityUCI.csv resources\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/lr_train.txt\n",
    "!mv lr_train.txt resources/\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/resources/lr_test.txt\n",
    "!mv lr_test.txt resources/\n",
    "!wget https://raw.githubusercontent.com/lompabo/bbs2019dtm/master/lab02/lutil.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to load and preprocess the data. This time, we will take two non-contiguous time steps, namely te current one and the one 24 hours earlier.\n",
    "\n",
    "Note that, since we are dropping all rows containin NaN values, the sequence will be off at times: it would be better to apply the sliding window to each block of contiguous rows separately, but for this exercise we will choose simplicity over correctness.\n",
    "\n",
    "Start by trying to learn a linear and a tree-based (random forest) regressor for the univariate case. Then see what happens by including additional features. Try to manage overfitting for the Random Forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of the input data: (803, 2, 1)\n",
      "Original shape of the output data: (803, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lompa/Documents/Teaching/BBS 2019 - Master in Digital Technology Management/lab02/lutil.py:209: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  x = np.stack( (data[i:-totwidth+i+1 or None:sliding_step] for i in steps_in), axis=1)\n",
      "/Users/lompa/Documents/Teaching/BBS 2019 - Master in Digital Technology Management/lab02/lutil.py:210: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  y = np.stack( (data[i:-totwidth+i+1 or None:sliding_step][targets] for i in steps_out), axis=1)\n"
     ]
    }
   ],
   "source": [
    "import lutil\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "data = lutil.load_air_data()\n",
    "data = data.dropna() # Discard tuples with NaN values\n",
    "\n",
    "# Univariate time series (discard all columns but one)\n",
    "data = data[['CO(GT)']]\n",
    "\n",
    "# Choose a separator date for the training and test set\n",
    "# NOTE: it's important to compute the means and standard deviations only on the training data!\n",
    "sep = data.index[-500]\n",
    "\n",
    "# Standardize the data\n",
    "means = data[data.index < sep].mean(axis=0)\n",
    "stds = data[data.index < sep].std(axis=0)\n",
    "data = (data - means) / stds\n",
    "\n",
    "# Build a dataset using a sliding window approach\n",
    "targets = ['CO(GT)']\n",
    "steps_in = [0,23]\n",
    "index, x_all, y_all = lutil.sliding_win_ds(data, targets, steps_in)\n",
    "\n",
    "print('Original shape of the input data: %s' % str(x_all.shape))\n",
    "print('Original shape of the output data: %s' % str(y_all.shape))\n",
    "\n",
    "x_all = x_all.reshape(len(x_all), -1)\n",
    "y_all = y_all.reshape(len(y_all), -1)\n",
    "\n",
    "# Separate training and test set\n",
    "train_mask = index < sep\n",
    "x_train, y_train = x_all[train_mask], y_all[train_mask]\n",
    "index_train = index[train_mask]\n",
    "test_mask = index >= sep\n",
    "x_test, y_test = x_all[test_mask], y_all[test_mask]\n",
    "index_test = index[test_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to train a linear regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE, training set (model): 0.465213\n",
      "MAE, test set (model): 0.454466\n",
      "R2, training set (model): 0.553735\n",
      "R2, test set (model): 0.625124\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Build the model\n",
    "model = linear_model.LinearRegression()\n",
    "# Training\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Obtain predictions\n",
    "pred_train = model.predict(x_train)\n",
    "pred_test = model.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "mae_train = metrics.mean_absolute_error(y_train, pred_train)\n",
    "r2_train = metrics.r2_score(y_train, pred_train)\n",
    "\n",
    "mae_test = metrics.mean_absolute_error(y_test, pred_test)\n",
    "r2_test = metrics.r2_score(y_test, pred_test)\n",
    "\n",
    "print('MAE, training set (model): %f' % (mae_train))\n",
    "print('MAE, test set (model): %f' % (mae_test))\n",
    "print('R2, training set (model): %f' % (r2_train))\n",
    "print('R2, test set (model): %f' % (r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how to train a Random Forest regressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE, training set (model): 0.230954\n",
      "MAE, test set (model): 0.527681\n",
      "R2, training set (model): 0.873783\n",
      "R2, test set (model): 0.446821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Build the model\n",
    "model = ensemble.RandomForestRegressor()\n",
    "# Training\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Obtain predictions\n",
    "pred_train = model.predict(x_train)\n",
    "pred_test = model.predict(x_test)\n",
    "\n",
    "# Evaluate\n",
    "mae_train = metrics.mean_absolute_error(y_train, pred_train)\n",
    "r2_train = metrics.r2_score(y_train, pred_train)\n",
    "\n",
    "mae_test = metrics.mean_absolute_error(y_test, pred_test)\n",
    "r2_test = metrics.r2_score(y_test, pred_test)\n",
    "\n",
    "print('MAE, training set (model): %f' % (mae_train))\n",
    "print('MAE, test set (model): %f' % (mae_test))\n",
    "print('R2, training set (model): %f' % (r2_train))\n",
    "print('R2, test set (model): %f' % (r2_test))\n",
    "\n",
    "# Plot importance scores\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(x_train.shape[1]), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(x_train.shape[1]), indices)\n",
    "plt.xlim([-1, x_train.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
